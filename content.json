{"meta":{"title":"Arexstorm个人工作站","subtitle":"","description":"","author":"Arexstorm","url":"http://sandiegoe.github.io","root":"/"},"pages":[{"title":"","date":"2022-05-23T02:52:01.144Z","updated":"2022-05-23T02:52:01.144Z","comments":true,"path":"TODO.html","permalink":"http://sandiegoe.github.io/TODO.html","excerpt":"","text":"待完成 Redis Redis持久化机制解析(RDB和AOF) Redis AKF原理解析 Redis主从模式解析及哨兵 Redis Cluster解析 缓存常见问题：击穿、穿透和雪崩应对策略 Redis如何实现分布式锁以及redisson介绍 Redis源码解析 J2Cache J2Cache两级缓存架构框架解析 https://gitee.com/ld/J2Cache#https://gitee.com/ld/J2Cache/blob/master/core/src/net/oschina/j2cache/J2CacheCmd.java MySQL JVM 多线程 算法 系统IO Zookeeper Seatunnel seatunnel整体架构介绍"},{"title":"分类","date":"2022-05-15T16:19:06.335Z","updated":"2022-05-15T16:19:06.335Z","comments":false,"path":"categories/index.html","permalink":"http://sandiegoe.github.io/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2022-05-15T16:18:56.079Z","updated":"2022-05-15T16:18:56.079Z","comments":false,"path":"tags/index.html","permalink":"http://sandiegoe.github.io/tags/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-05-15T16:18:49.535Z","updated":"2022-05-15T16:18:49.535Z","comments":false,"path":"about/index.html","permalink":"http://sandiegoe.github.io/about/index.html","excerpt":"","text":"个人详细介绍"}],"posts":[{"title":"Redis持久化机制解析(RDB和AOF)","slug":"Redis持久化机制解析-RDB和AOF","date":"2022-05-23T00:24:00.000Z","updated":"2022-05-23T02:52:54.931Z","comments":true,"path":"2022/05/23/Redis持久化机制解析-RDB和AOF/","link":"","permalink":"http://sandiegoe.github.io/2022/05/23/Redis%E6%8C%81%E4%B9%85%E5%8C%96%E6%9C%BA%E5%88%B6%E8%A7%A3%E6%9E%90-RDB%E5%92%8CAOF/","excerpt":"","text":"Redis持久化的几种方式 Redis支持两种方式持久化，分别是RDB和AOF，各有优缺点。通过持久化，可以避免Redis缓存数据丢失，保证数据安全。 RDB 特点 RDB是将当前进程内的数据生成一份快照保存到磁盘上 时点性：间隔固定时间或者指定次数操作后触发 配置 123456`save m n`：m秒内执行n次操作触发bgsave`stop-writes-on-bgsave-error yes``rdbcompression yes``rdbchecksum yes``dbfilename dump.rdb``dir /var/lib/redis/6379` 流程 执行bgsave命令 父进程会fork一个子进程，fork期间是阻塞的，info stats查看latest_fork_usec获取最近一个fork操作的耗时，单位是微妙 父进程fork完，bgsave命令返回&quot;Background saving started&quot; 子进程创建rdb文件，并替换原有的rdb文件 子进程发送信号给父进程表示完成，更新统计信息 触发 有两种方式触发，一种手动，一种通过配置的策略自动触发 手动 save: 阻塞方式生成快照，生成快照期间，客户端查询将会被阻塞 bgsave: 非阻塞方式生成快照 自动 在redis配置文件中配置触发规则 save m n：m秒内发生n次操作就触发生成快照，非阻塞方式 从节点执行全量复制 当从节点执行全量复制时，主节点会执行bgsave debug reload 执行debug reload重新加载Redis时，也会触发save操作 shutdown 默认情况执行shutdown，如果没有配置AOF也会自动执行bgsave 优缺点 优点 是一个紧凑的二进制文件，代表某个时间点上的快照，试用于备份 相比于AOF恢复速度快 缺点 容易丢失数据：在生成下一次快照之前，如果Redis发生故障，在这段时间内的数据会丢失 不支持拉链：只会保留最新的一个rdb文件 AOF 特点 AOF是另外一种持久化方式，它是以日志文件的格式来记录Redis操作的命令，当redis重启时，通过重新执行日志文件中的命令来恢复数据 在redis中，AOF和RDB可以同时开启 如果开启了AOF，那么只会用AOF来恢复 在Redis4.0以后，AOF文件中包含RDB全量，以及之后的增量操作日志 配置 appendonly yes：开启AOF appendfilename &quot;appendonly.aof&quot;：aof文件名称 appenddirname &quot;appendonlydir&quot;：持久化AOF文件目录 appendfsync：刷盘策略，默认是everysec no-appendfsync-on-rewrite no auto-aof-rewrite-min-size 64mb：表示运行AOF重写时文件最小的体积 auto-aof-rewrite-percentage 100：表示当前AOF文件大小(aof_current_size)和上一次重写之后的AOF文件空间(aof_base_size)的比值 aof-load-truncated yes 刷盘策略 everysec 每秒钟进行一次刷盘，将aof_buffer中的数据写到磁盘中，最多丢失1s内的数据 no 依赖操作系统自己的fsync机制 always 每加一个，就刷一次 流程 写命令会追加到aof_buffer中 aof_buffer会根据对应的策略向硬盘做同步操作 随着文件越来越大，aof文件会进行重写，达到压缩目的 当redis重启时，会加载读取aof文件来恢复数据 重写机制 重启加载 触发 手动 bgrewriteaof 自动 根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage 100参数来自动触发 触发时机：aof_current_size &gt; auto-aof-rewrite-min-size &amp;&amp; (aof_current_size - aof_base_size) / aof_base_size &gt;= auto-aof-rewrite-percentage 优缺点 优点 数据不易丢失 缺点 恢复速度慢 文件体积大 类比hdfs fsimage + edits.log，让日志只是记录增量的部分 4.0前 aof文件重写，删除抵消的命令，合并重复的命令，最终得到也是一个纯指令的日志文件 4.0以后 重写，将老的数据rdb到aof文件中，增量以指令的方式追加到aof文件。aof文件是一个混合体，利用了rdb的快，利用了日志到全量 fork子进程 父进程fork出子进程时，此时并不会拷贝内存数据，夫子进程都可以访问内存中的数据，且是一致的。当某个进程修改数据的时候，会使用copy on write技术，先copy出一份数据，然后再修改，确保自己的修改不会影响到其它进程。 管道 起到连接作用，前一个命令的输出作为第二个命令的输入 管道会触发创建子进程 123456echo $$echo $BASHPID# $$ 优先级高于 | echo $$ | more echo $BASHPID | more linux父子进程 父进程的数据，子进程能否看到？ 常规思想，进程的数据是相互隔离的 进阶思想，父进程可以让子进程看到数据 在linux中，export的环境变量，子进程的修改不会影响父进程，父进程的修改也不会影响子进程 redis中fork子进程，速度很快，占用空间很小 fork.sh 1234567#!/bin/bashecho &quot;bashpid $BASHPID&quot;echo &quot;child start $num&quot;sleep 30echo &quot;child second $num&quot;num=888echo &quot;child end $num&quot; 调用 12345678910num=999echo $BASHPIDecho $num export numecho $num./fork.sh &amp;echo $numnum=10echo $num","categories":[{"name":"缓存","slug":"缓存","permalink":"http://sandiegoe.github.io/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://sandiegoe.github.io/tags/Redis/"},{"name":"RDB","slug":"RDB","permalink":"http://sandiegoe.github.io/tags/RDB/"},{"name":"AOF","slug":"AOF","permalink":"http://sandiegoe.github.io/tags/AOF/"}]},{"title":"Redis的两种使用场景：缓存和数据库","slug":"Redis的两种使用场景：缓存和数据库","date":"2022-05-22T14:30:34.000Z","updated":"2022-05-22T14:57:41.081Z","comments":true,"path":"2022/05/22/Redis的两种使用场景：缓存和数据库/","link":"","permalink":"http://sandiegoe.github.io/2022/05/22/Redis%E7%9A%84%E4%B8%A4%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF%EF%BC%9A%E7%BC%93%E5%AD%98%E5%92%8C%E6%95%B0%E6%8D%AE%E5%BA%93/","excerpt":"","text":"Redis的使用场景 Redis有两种典型的使用场景，一个是把Redis作为缓存来使用，另一个是把Redis作为数据库来使用。针对不同使用场景，对于Redis的要求也是不一样的。 作为缓存 特点 缓存的数据不重要，是允许丢的 不是全量数据 随着请求缓存的数据会变化：内存大小是有限制的，不可能一直放，将热点数据放入缓存，非热点数据移除缓存 存放的是热数据 随着请求缓存的数据会变化 业务逻辑 key是有有效期的 key的访问不会影响缓存key的过期时间 key更新，会移除key的过期时间，如果更新的时候未指定过期时间 有效期随着时间不断减少，到达时间，key就被淘汰了 可以实现定时，比如统一24:00过期 怎么实现过期？ 被动：访问该key的时候，判断有没有过期，如果过期自动删掉并返回空 主动：通过轮询，周期性的方式来扫描过期的key来删除 业务运转 内存是有限的，随着访问应该要淘汰掉冷数据 maxmemory bytes：设置Redis最大内存 maxmemory-policy：到达最大内存之后，对应的淘汰策略是什么 Redis几种内存淘汰策略 noeviction 不驱逐任何key，客户端返回异常 作为数据库 特点 数据很重要，不能丢失，一丢失就影响业务了 追求速度和持久性 需要开启RDB或者AOF","categories":[{"name":"缓存","slug":"缓存","permalink":"http://sandiegoe.github.io/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://sandiegoe.github.io/tags/Redis/"},{"name":"数据库","slug":"数据库","permalink":"http://sandiegoe.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"缓存","slug":"缓存","permalink":"http://sandiegoe.github.io/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"Redis布隆过滤器","slug":"Redis布隆过滤器","date":"2022-05-17T17:24:39.000Z","updated":"2022-05-22T15:00:51.605Z","comments":true,"path":"2022/05/18/Redis布隆过滤器/","link":"","permalink":"http://sandiegoe.github.io/2022/05/18/Redis%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/","excerpt":"","text":"什么是布隆过滤器 有时候我们可能希望快速判断某个key是否存在我们系统内，一种直观的想法是，拿着这个key到相应存储中查一遍，能查到，就说明存在，查不到则说明不存在。那么有没有一种更简单的方式来实现呢，因为有时候通过数据库查询的开销可能比较大。布隆过滤器就是一个比较好的选择，可以快速判断某个key是否存在，当然它并不是完全准确，有一定的误差。 实现原理 添加 它会维护一个bitmap，当我们添加key的时候，会通过多个映射函数，计算出这个key在bitmap中的位置，并将相应位置的设置成1 查询 当查询一个key的时候，同样会经过映射函数，计算该key在bitmap中的位置，当全部位置为1的时候，表示该key已经存在，当有一个位置为0时，表示该key不存在 布隆过滤器的几种结合方式 client端完成 在客户端维护bitmap，并实现布隆过滤器的算法 client端算法,Redis保存bitmap 在redis中保存bitmap信息，在客户端来实现布隆过滤器算法 Redis Bloom模块 通过Redis Bloom模块完成bitmap的存储和算法实现 注意事项 不能删除key 不存在是精确的，存在是不精确的：通过布隆过滤器判断某个key存在时，不一定真的存在，有可能是对应的位被其他key置成了1，存在误差。这个误差和bitmap位数和放入key的数量相关 有哪些key，需要事先向bitmap中来标记 请求有可能会被误标记 概率解决问题，不可能100%阻挡 在一定概率上会大量减少因为穿透导致的放行 实现成本低 布隆过滤器怎么用 RedisBloom布隆过滤器仓库地址 https://github.com/RedisBloom/RedisBloom 安装布隆过滤器模块 123456wget https://github.com/RedisBloom/RedisBloom/archive/refs/tags/v2.0.3.tar.gztar -zcvf v2.0.3.tar.gzcd RedisBloom-2.0.3make cp redisbloom.so /opt/redis7redis-server --loadmodule /opt/redis7/redisbloom.so 使用 bf.add：把某个key添加到布隆过滤器中 bf.exists：判断某个key是否存在 使用场景 缓存穿透 缓存穿透指的是用户请求的数据即不在缓存，也不在数据库内，导致每次请求都需要查询数据库。 解决办法 布隆过滤器 通过布隆过滤器判断某个key是否存在，当布隆过滤器返回不存在时，直接返回，不再触发数据库查询。当然不能100%阻拦这种查询，还是有一定概率会发起数据库的查询，但是能够阻拦大部分请求。 空对象 第一次访问不存在的时候，直接在缓存中放一个空内容。后续请求全部走Redis查询，返回空内容。 对比","categories":[{"name":"缓存","slug":"缓存","permalink":"http://sandiegoe.github.io/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://sandiegoe.github.io/tags/Redis/"},{"name":"模块","slug":"模块","permalink":"http://sandiegoe.github.io/tags/%E6%A8%A1%E5%9D%97/"}]},{"title":"Redis事物解析","slug":"Redis事物解析","date":"2022-05-17T16:40:54.000Z","updated":"2022-05-22T13:36:29.831Z","comments":true,"path":"2022/05/18/Redis事物解析/","link":"","permalink":"http://sandiegoe.github.io/2022/05/18/Redis%E4%BA%8B%E7%89%A9%E8%A7%A3%E6%9E%90/","excerpt":"","text":"Redis的事物是什么 什么是事物？ 事物中包含了一组操作，这些操作要么全部执行，要么全部不执行，实现这样的效果就称作为事物。 Redis和事物的关系 Redis支持简单的事物，为什么说简单呢？因为Redis不支持事物的回滚。Redis的设计理念是为了追求性能，支持完成的事物，会增加系统的复杂度，对于性能也会有影响，因此在使用Redis事物的时候需要特别注意。 事物中的操作记录在哪 Redis是单线程的，不同客户端的事物彼此之间是相关隔离、相互独立的。当一个客户端开启了一个事物，客户端在exec之前提交的命令会放到一个缓冲区中，当客户端执行exec，Redis Server会执行事物中的所有操作。对于Redis来说，不同的事物都是排队在执行。 多个客户端事物的执行顺序 通过前面的描述，我们知道当客户端执行exec时，会触发Redis执行事物中的操作。因此Redis Server对于多个客户端提交的事物，会看哪个事物先执行exec，对于Redis来说时单线程来执行，肯定会有一个事物提交exec。当Redis Server接收到事物的exec命令时，就会执行该事物的所有操作，即使该事物的Multi可能比另外一个事物后提交。 Redis事物怎么用 help 1help @transactions 简单使用 multi：表示开启一个事物，后续可以跟若干个操作，这些操作并不会立即执行 exec：表示提交一个事物，Redis将会执行事物的所有操作 停止事物 discard：表示停止事物的执行 乐观锁 通过watch可以为实现实现一个类似乐观锁的效果，watch命令会观察某个key是否被其他客户端修改过，如果发生了修改，那么该事物不会执行，只有当该key没有被修改过，事物才能够执行。 123456set key javawatch key multiset k1 helloget keyexec","categories":[{"name":"缓存","slug":"缓存","permalink":"http://sandiegoe.github.io/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://sandiegoe.github.io/tags/Redis/"},{"name":"事物","slug":"事物","permalink":"http://sandiegoe.github.io/tags/%E4%BA%8B%E7%89%A9/"}]},{"title":"Redis发布订阅模型","slug":"Redis发布订阅模型","date":"2022-05-17T16:40:46.000Z","updated":"2022-05-18T14:13:12.987Z","comments":true,"path":"2022/05/18/Redis发布订阅模型/","link":"","permalink":"http://sandiegoe.github.io/2022/05/18/Redis%E5%8F%91%E5%B8%83%E8%AE%A2%E9%98%85%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"什么是发布订阅模型 Redis是支持发布订阅，发布的时候，先指定channel，然后发布消息；订阅的时候也需指定channel，当发布和订阅的是同一个channel时，发布者发送的消息会被所有已经订阅这个channel的客户端收到。 Redis发布订阅怎么用 help @pubsub pubsub channels：查询有哪些channel pubsub numsub：查看channel的订阅数 pubsub numpt：查看模式的订阅数 发布 publish：指定channel以及需要发送的消息 订阅 subscribe：可以指定多个channel psubscribe：支持按照模式订阅 注意事项 订阅者无法收到历史消息，也就是只有监听channel之后发送的消息才能被接收到 Redis不会对消息进行持久化 和Kafka，RabbitMQ等消息队列相比，Redis的功能比较简单。如果使用场景对于消息的持久化、消息的回溯不关心，那么Redis是一个不错的选择。 具体案例 聊天室 公告牌 服务之间的解耦合","categories":[{"name":"缓存","slug":"缓存","permalink":"http://sandiegoe.github.io/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://sandiegoe.github.io/tags/Redis/"},{"name":"pub/sub","slug":"pub-sub","permalink":"http://sandiegoe.github.io/tags/pub-sub/"}]},{"title":"Redis Pipeline解析","slug":"Redis Pipeline解析","date":"2022-05-17T16:40:36.000Z","updated":"2022-05-18T13:46:49.334Z","comments":true,"path":"2022/05/18/Redis Pipeline解析/","link":"","permalink":"http://sandiegoe.github.io/2022/05/18/Redis%20Pipeline%E8%A7%A3%E6%9E%90/","excerpt":"","text":"Pipeline是什么 Pipeline也叫做流水线，它可以将一组redis命令进行封装，然后一次性的发送给Redis Server。假设我们需要访问10条redis key数据，一种常见的做法是每条key，客户端发送一条get请求取回数据，循环10次，取出全部的数据。如果有了Pipeline就可以将这10条get命令封装一个请求，一次性的发送到Redis Server，Redis Server接收到这个请求之后，收集10条命令的结果一次性的返回给客户端。 为什么需要Pipeline 请求过程 Redis客户端发起请求到Redis Server反悔结果，中间大概可以划分四个步骤： 第一步：Redis客户端将请求发送Redis Server 第二步：Redis Server接收请求，命令排队 第三步：Redis Server执行命令 第四步：Redis Server将执行的结果返回给客户端 其中第一步和第四步都是需要有网络，称之为RTT(Round Trip Time， 往返时间) 优势 当多个命令可以合并的时候，就可以不用每次都需要发送命令，返回结果。此时通过Pipeline将多个命令合并成一个请求，减少了网络交互次数，节省网络开销，提高了效率。特别是针对网络时延比较明显的大的，效果更显著 使用场景 初始化数据 注意事项 Pipeline中包含的命令也不能过大，增大了等待时间，也会造成一定的网络堵塞 怎么使用 nc nc，全称是netcat。当没有redis-cli客户端的时候，也可以通过nc向Redis Server发送命令。Redis Server默认端口是6379。 123456789yum install ncnc localhost 6379keys **0set a 1+OKget a $11 Pipeline 1echo -e &quot;get a\\nset a 20\\nget a\\nflushdb&quot; | redis-cli --pipe","categories":[{"name":"缓存","slug":"缓存","permalink":"http://sandiegoe.github.io/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://sandiegoe.github.io/tags/Redis/"},{"name":"Pipeline","slug":"Pipeline","permalink":"http://sandiegoe.github.io/tags/Pipeline/"}]},{"title":"Redis数据类型","slug":"Redis数据类型","date":"2022-05-15T13:37:12.000Z","updated":"2022-05-17T14:55:02.331Z","comments":true,"path":"2022/05/15/Redis数据类型/","link":"","permalink":"http://sandiegoe.github.io/2022/05/15/Redis%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"Redis是一种K、V型数据库，针对V Redis内置了多种数据类型，常见的如string、list、set、zset等。K上会包含一个type，用来表示V的类型，还会包含encoding，表示V的编码格式 string string表示的是value的类型，string有三类操作，针对字符串、针对数值和针对bitmap help @string sting =&gt; byte string内部也包含三种：字符串、数值和bitmap 字符串 set get append setrange getrange strlen：看的是有多少个字节，abcd长度为4，99999长度为5 正反向索引： 正向索引：0、1、2、3 反向索引：-1、-2、-3 type命令 type k1: 返回k1表示的value的类型 object object encoding k1: 返回k1表示的value的编码 二进制安全 redis进程和外界交互的时候，使用的是字节流，底层存储也是二进制字节，通过encoding可以辅助判断，如果是int，可以直接incr，能够提高速度 中文一个字符utf8是三个字节，gbk是两个字节 hbase也是二进制安全的 数值 incr：抢购、秒杀、商品详情，点赞，评论数、好友数，规避并发下对数据库的事物操作，计算向数据移动，完全由redis来替代 incrby incrbyfloat decr decrby bitmap help setbit setbit bitcount：返回start-end字节中统计1出现的次数 bitpos：返回第start-end字节的bit为指定值的位置 bitop：bitop operation destkey key [key …]，执行bit操作，operation与或非，destkey写入的目标key，key参与运算的key 12345setbit k1 1 1strlen k1 =&gt; 1getbit k1 =&gt; @setbit k1 9 1 strlen k1 =&gt; 2 man ascii 使用场景 用户系统：统计用户的登录天数，且窗口随机 618活动，登录就送礼物：仓库备货多少礼物，假设2亿用户 僵尸用户、冷热用户/忠诚用户 活跃用户统计，随机窗口 以天为key，每个key中的每个bit表示每个用户，需要做用户和bit的下标做映射 list list是有序(说的是插入的顺序)，能够保存重复元素，为list类型的key会包含两个属性，head，tail用来指向链表的头节点和尾节点。 常用命令 help @list lpush：往左边添加元素 rpush：往右边添加元素 lpop：弹出一个左边的元素 rpop：弹出一个右边的元素 lrange：看start-end的元素集合 lindex：查看某个索引位置的元素 lset：设置某个索引位置的元素 lrem：从list中移除count个元素，其值为value；count为正数，从左往右，为负数，从右往走 linsert：从某个位置插入一个元素 llen blpop：阻塞的左边弹 ltrim：移除start-end两端等数据 使用场景 栈 可以用list来表示栈结构，使用同向命令 队列 用list来表示队列，使用反向命令 数组 用list来表示数组，通过下标lindex, lset等 阻塞 单播队列 FIFO 使用blpop、lpush hash 类似java中的HashMap，健值对形式 常用命令 hset hmset hget hmget hkeys kvals hgetall hincrbyfloat 使用场景 对field进行数值计算 商品详情页 点赞、收藏、分享数 set 是一个集合，集合内的元素不重复，无序。 常用命令 sadd smembers srem scard sinter：取集合交集 sinterstore：交集的结果存储到某一个key里，没有IO sunion：取集合到并集 sunionstore sdiff：返回集合的差集 srandomemember：随机返回一个集合中的元素，count为正数，取出一个去重的结果集（不能超过已有的结果集），count负数，可以取出一个带重复的结果集合，一定满足你要的数量，如果count为0，就不返回 spop 使用场景 抽奖(一次抽多个) 使用srandomemember来实现，一个key中存放粉丝用户，+3 给你返回三个且去重，-3 给你反回允许重复 抽奖(一次抽一个，不能重复抽) spop sorted set(zset) 去重且有序，按照score来进行排序。在内存里是按照链表来存储，默认左小右大的物理摆放顺序 常用命令 zadd zrange zrangebyscore zrevrange zscore zrank：取出排名 zincrby zunionstore 排序怎么实现的 底层是通过skiplist跳跃表(类平衡树)数据结构来实现的。每个元素插入的时候随机造层，越往上，节点数越少。针对增删改大量操作，平均值相对最优。 使用场景 榜单 使用zrevrange命令取出前N","categories":[{"name":"缓存","slug":"缓存","permalink":"http://sandiegoe.github.io/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://sandiegoe.github.io/tags/Redis/"}]},{"title":"Redis原理","slug":"Redis原理","date":"2022-05-15T10:21:20.000Z","updated":"2022-05-16T06:19:22.678Z","comments":true,"path":"2022/05/15/Redis原理/","link":"","permalink":"http://sandiegoe.github.io/2022/05/15/Redis%E5%8E%9F%E7%90%86/","excerpt":"","text":"Redis相关的原理 一台Linux机器上面可以跑多个Redis进程，多个实例。针对单个Redis来说，是单进程，单线程，单实例。客户端可能会有很多个，可能以socket fd形式，连到系统kernel上，redis通过epoll来取数据，单线程，顺序来读取。 顺序性：每个连接内的命令是顺序的 =》衍生kafka topic 分区消息顺序性 使用 启动 通过 redis-cli 命令启动客户端 切换库 redis默认是有16个库，0～15 redis-cli -db select db 不同db之间数据是隔离的 help 通用：help @generic value: help @sting @list @hash Linux BIO 每个连接对应一个线程，Socket在这个时期是blocking的。 同步非阻塞 NIO 对应一个线程，不用阻塞，不用很多的线程。会轮询调用kernel, 检查fd有没有数据。比如有1000个fd，代表用户进程轮询调用1000次kernel。一个线程可以hold住1000个连接，避免每个连接对应一个线程，增加系统成本。在这个期间，会涉及用户和内核空间转换，上下文切换等等，有系统开销，成本比较大。 轮询是发生在用户空间。 线程多了，cpu调度成本高，频繁做线程切换，内存成本高，一个线程占用1MB内存。 多路复用 NIO 调用系统内核的select，将上面的1000个文件描述符全部传进来。只会调用一次，在内核态等待，再返回fd，然后用户空间再通过read调用挨个访问fd。在这个过程中还是会涉及到fd相关的数据拷贝来拷贝去。 epoll epoll create create epfd ctl ctl add delete socket fd wait 等待事件，数据准备好了，放到链表，就可以返回了。 MMAP共享空间 划分出来一个共享空间，内核和用户都可以直接访问。上面的1000个文件描述符直接写入到共享空间，内核直接通过地址访问这个共享空间，避免了fd相关数据的拷贝。 使用红黑树来表示文件描述符 使用链表来表示已经读取好的文件描述符 零拷贝","categories":[],"tags":[]},{"title":"Redis入门","slug":"Redis入门","date":"2022-05-15T06:24:35.000Z","updated":"2022-05-15T07:33:27.353Z","comments":true,"path":"2022/05/15/Redis入门/","link":"","permalink":"http://sandiegoe.github.io/2022/05/15/Redis%E5%85%A5%E9%97%A8/","excerpt":"","text":"Redis常识 为什么需要Redis？ 在软件架构里，数据通常存储在数据库里。数据库存储在磁盘文件里，会受到磁盘IO的影响，存在性能瓶颈。当访问量特别大的时候，频繁访问数据库，磁盘IO比较高，查询性能比较慢。这时候可以适当加上缓存，Redis就是个不错的选择。可以将经常查询的数据放在Redis里，借助Redis数据放在内存，提供的高效的查询能力助力业务。 遇到的问题 引入Redis之后，需要面对一个问题，如何保证数据库和缓存数据的一致性？ 和IO相关的知识 磁盘 说的磁盘会有两个和磁盘相关的指标，一个是寻址，一个是带宽 寻址：一般是在毫秒级别 带宽：单位时间内流过的数据量，一般是G或者MB 内存 内存同样也会有这两个指标 寻址：一般是在纳秒级别 带宽：很大 在寻址方面内存会比磁盘快10W倍。 I/O buffer 磁盘会有磁道和扇区，一个扇区512字节。如果这个容量太小，扇区数就会增加，索引就会增大，会增加管理的成本。 操作系统读取写入数据一般是按照4K个字节为单位来进行存取，即使只需要少量几个字节的信息，也会一次性的读取整个4K字节，提高访问速度。我们在进行磁盘格式化的时候，需要做分区对齐，一般也是4K。 随着磁盘中文件越来越大，访问速度会变慢？这是因为此时磁盘IO成为了瓶颈。 和数据库相关的知识 数据存储 当我们往数据库里放数据，首先需要为其创建一张表，定义好schema，表中包含哪些字段，类型是什么。存储的时候倾向按行来存储，将一条数据包含的所有内容，按照行的形式存到文件里。具体的存储格式和数据库存储引擎相关。 数据查询 当查询没有命中索引，会进行全表扫描，磁盘IO是比较大的。当命中索引时，可以通过索引快速查询出需要的数据，减少不必要的IO。MySQL数据库Innodb存储引擎，索引是通过B+树来实现的，每个节点可以有多个分叉，只有叶子结点存储数据，非叶子结点不存储数据，实现了用很少的层数来索引大量的数据。三层B+树，就可以来表示千万级别的数据量。 表很大，性能下降？ 增删改 有索引，增删改的成本会变高，因为涉及到维护索引。 查询 单个或者少量的查询还是很快，并发大的时候会受到磁盘带宽的影响，速度会变慢（数据量大，即使通过索引命中的数据可能也比较多）。 Redis安装 Redis官网 redis.io 安装步骤 123456789101112131415161718192021222324252627# 1.下载安装包 wget https://github.com/redis/redis/archive/7.0.0.tar.gz# 2.解压缩安装包 tar -zxvf redis-7.0.0.tar.gz# 3.查看README.mdcat README.md# 4.编译安装yum install gccmake make install PREFIX=/opt/redis7make test make distclean# 5.配置环境变量vi /etc/prifileexport REDIS_HOME=/opt/redis7export PATH=$PATH:$REDIS_HOME/binsource /etc/profile# 6.配置系统服务sh utils/install_server.sh# 7.启动停止redisservice redis_6379 start/stop/restart/status This systems seems to use systemd","categories":[],"tags":[]},{"title":"动态年龄","slug":"动态年龄","date":"2022-01-28T07:32:12.000Z","updated":"2022-01-28T07:32:12.067Z","comments":true,"path":"2022/01/28/动态年龄/","link":"","permalink":"http://sandiegoe.github.io/2022/01/28/%E5%8A%A8%E6%80%81%E5%B9%B4%E9%BE%84/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"标量替换","slug":"标量替换","date":"2022-01-28T07:31:19.000Z","updated":"2022-01-28T07:31:19.565Z","comments":true,"path":"2022/01/28/标量替换/","link":"","permalink":"http://sandiegoe.github.io/2022/01/28/%E6%A0%87%E9%87%8F%E6%9B%BF%E6%8D%A2/","excerpt":"","text":"","categories":[],"tags":[]}],"categories":[{"name":"缓存","slug":"缓存","permalink":"http://sandiegoe.github.io/categories/%E7%BC%93%E5%AD%98/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://sandiegoe.github.io/tags/Redis/"},{"name":"RDB","slug":"RDB","permalink":"http://sandiegoe.github.io/tags/RDB/"},{"name":"AOF","slug":"AOF","permalink":"http://sandiegoe.github.io/tags/AOF/"},{"name":"数据库","slug":"数据库","permalink":"http://sandiegoe.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"缓存","slug":"缓存","permalink":"http://sandiegoe.github.io/tags/%E7%BC%93%E5%AD%98/"},{"name":"模块","slug":"模块","permalink":"http://sandiegoe.github.io/tags/%E6%A8%A1%E5%9D%97/"},{"name":"事物","slug":"事物","permalink":"http://sandiegoe.github.io/tags/%E4%BA%8B%E7%89%A9/"},{"name":"pub/sub","slug":"pub-sub","permalink":"http://sandiegoe.github.io/tags/pub-sub/"},{"name":"Pipeline","slug":"Pipeline","permalink":"http://sandiegoe.github.io/tags/Pipeline/"}]}